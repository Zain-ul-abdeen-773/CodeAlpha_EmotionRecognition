# ğŸ¤ Speech Emotion Recognition Flask App

This web app recognizes human emotions (e.g., Happy, Sad, Angry) from uploaded audio using deep learning. It features a beautiful animated UI, waveform visualization, voice feedback, and supports both `.wav` and `.mp3`.

---

## ğŸš€ Features

* ğŸŒŸ Predicts 7 emotions: `angry`, `boredom`, `disgust`, `fear`, `happy`, `neutral`, `sad`
* ğŸ§ Supports `.wav` and `.mp3` audio files
* ğŸ“Š Visualizes waveform of the voice
* ğŸ§  Trained **Bidirectional LSTM** model
* ğŸ”ˆ Speaks out prediction: â€œYou are sad nowâ€
* ğŸŒˆ Fully animated neon UI (responsive)
* ğŸ” Uploads are temporary & private

---

## ğŸ® Demo

![waveform](static/waveform.png)

> âœ¨ The waveform is generated automatically from the uploaded voice.

---

## ğŸ§  Model Architecture

The model is a **Bidirectional LSTM** with MFCC + delta features as input.

```plaintext
Input Layer: (160, 60)    â† MFCC + delta + deltaÂ²
â†“
Bidirectional LSTM (128 units)
â†“
Dropout (0.3)
â†“
Dense (64) + ReLU
â†“
Dense (7) + Softmax
â†“
Output: Emotion Class
```

> Trained using EMO-DB (Berlin Database of Emotional Speech)

---

## ğŸ“‚ Dataset

We used the [EMO-DB Dataset (Berlin Emotional Speech Corpus)](https://www.kaggle.com/datasets/johnnyko28/emodb-emotional-berlin-database) with 7 emotional labels.

Other recommended datasets:

* [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
* [TESS](https://www.kaggle.com/datasets/chekagust/tess)

---

## ğŸ“ Project Structure

```
emotion_app/
â”œâ”€â”€ app.py
â”œâ”€â”€ model/
â”‚   â””â”€â”€ emotion_bilstm_final_model.keras
â”œâ”€â”€ static/
â”‚   â””â”€â”€ waveform.png         â† Auto-generated
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           â† Animated UI
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ (Temporary audio)
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

1. **Install dependencies**

```bash
pip install flask librosa tensorflow matplotlib pyttsx3 ffmpeg-python
```

2. **Install FFmpeg** (for mp3 support):

* Windows: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

---

## ğŸ”§ Run the App

1. Clone the repo:

```bash
git clone https://github.com/yourusername/emotion-recognition-app.git
cd emotion-recognition-app
```

2. Put your trained model in `model/emotion_bilstm_final_model.keras`

3. Run the app:

```bash
python app.py
```

4. Open in browser:
   [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸ§° How It Works

1. Upload an audio file (`.wav` or `.mp3`)
2. Features (MFCCs + delta + deltaÂ²) are extracted
3. Bidirectional LSTM predicts emotion
4. Result is spoken out
5. Waveform is plotted and displayed

---

## ğŸ“Œ Roadmap / Future Add-ons

* ğŸ§ Real-time mic input recording
* ğŸ“Š Probability bar chart
* ğŸ½ Emoji / avatars based on mood
* ğŸ§¹ Hugging Face or Render deployment
* ğŸ“ƒ Upload history or emotion log
* ğŸ¿ Voice pitch analysis

---

## ğŸ“· Screenshots

| Upload Form                  | Result + Waveform        |
| ---------------------------- | ------------------------ |
| ![](static/form-preview.png) | ![](static/waveform.png) |

---

## â˜ Deployment Ideas

### ğŸŒ Host on Hugging Face Spaces

* Easy with Gradio UI version

### ğŸŒ Use Render.com

* Add `requirements.txt` and `Procfile`

---

## ğŸ‘¨â€ğŸ’¼ Author

**Zain ul Abdeen**
BS in Artificial Intelligence
ğŸš€ Passionate about AI, Deep Learning & Real-World Applications
ğŸ“§ [LinkedIn](#) | [Portfolio](#) | [Email](#)

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE)

---

## â­ Show Your Support

If you like this project, consider giving it a â­ on GitHub!
